{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3667800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_48268\\901055969.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df.drop(['Start_Time'], axis=1, inplace=True)\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_48268\\901055969.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df_before.drop(['Start_Time'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "# Step 0: Initial Reading of Data\n",
    "rti_final_df = pd.read_csv('RTI-final.csv')\n",
    "sa_zones_df = pd.read_csv('SA-zones.csv')\n",
    "\n",
    "# Step 1: Merging DataFrames\n",
    "df = pd.merge(rti_final_df, sa_zones_df, how='left', left_on='SA2_CODE21', right_on='0_ZID')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df['Start_Time'] contains Excel serial date numbers\n",
    "# Convert Excel serial date numbers to datetime\n",
    "# df['Start_Time'] = pd.to_datetime(df['Start_Time'], origin='1899-12-30', unit='D')\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='%d-%m-%Y %H:%M')\n",
    "# Now you can extract month and hour\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Replacing and Evaluating Lists More Safely\n",
    "# Replace unknown and \"[' ']\" with \"[]\"\n",
    "df['Attending_Groups'] = df['Attending_Groups'].replace({'unknown': '[]', \"[' ']\": \"['Other']\"})\n",
    "df['Attending_Groups'] = df['Attending_Groups'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Step 3: Dropping Unnecessary Columns Early (ensure they're not needed beyond this point)\n",
    "df = df.drop(['0_ZID', 'LOCI_URI21', 'SA2_NAME21', 'Other_Advice', 'Diversions', 'Attending_Groups', 'End_Time', 'Last_Updated', 'Incident ID'], axis=1)\n",
    "\n",
    "# Step 4: Extracting Info from Display Name\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "\n",
    "def extract_info_from_display_name(row):\n",
    "    incident_type = 'unknown'\n",
    "    num_vehicles_involved = 1  # Default to 1 if specific number is not mentioned\n",
    "\n",
    "    # Identifying the incident type\n",
    "    if 'breakdown' in row.lower():\n",
    "        incident_type = 'breakdown'\n",
    "    elif 'crash' in row.lower() or 'collision' in row.lower():  # Added 'collision' as a keyword\n",
    "        incident_type = 'crash'\n",
    "    elif 'accident' in row.lower():\n",
    "        incident_type = 'accident'\n",
    "\n",
    "    # Extract number of cars/vehicles if specified\n",
    "    numbers = re.findall(r'(\\d+)\\s*(cars|vehicles)', row, re.IGNORECASE)\n",
    "    if numbers:\n",
    "        num_vehicles_involved = int(numbers[0][0])\n",
    "    elif 'car' in row.lower() or 'vehicle' in row.lower():\n",
    "        num_vehicles_involved = 1\n",
    "\n",
    "    # Here you could encode the incident_type using LabelEncoder if needed\n",
    "    # encoder = LabelEncoder()\n",
    "    # incident_type_encoded = encoder.fit_transform([incident_type])[0]\n",
    "    # But for simplicity, we'll return the string type and number as is\n",
    "\n",
    "    return pd.Series([incident_type, num_vehicles_involved])\n",
    "\n",
    "# Apply and Create New Columns\n",
    "df[['Incident_Type', 'Num_Vehicles_Involved']] = df['Display_Name'].apply(extract_info_from_display_name)\n",
    "\n",
    "# Step 5: Label Encoding\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column].astype(str))\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Extract Month and Hour Information\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def extract_month_and_hour(start_time_str):\n",
    "    # Ensure start_time_str is a string\n",
    "    start_time_str = str(start_time_str)\n",
    "    \n",
    "    # Parse the datetime from the string\n",
    "    dt = datetime.strptime(start_time_str, '%d-%m-%Y %H:%M')\n",
    "    \n",
    "    # Return the month and hour as a pandas Series\n",
    "    return pd.Series([dt.month, dt.hour])\n",
    "\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "df['Hour'] = df['Start_Time'].dt.hour\n",
    "\n",
    "# Calculate Distance to CBD\n",
    "reference_point = (-33.87324469333478, 151.20665137317067)\n",
    "df['distance_to_CBD'] = df.apply(lambda row: geodesic((row['Latitude'], row['Longitude']), reference_point).km, axis=1)\n",
    "\n",
    "# Step 6: Identifying Imbalanced Columns & Dropping Them\n",
    "threshold = 0.95  # Correcting the comment to match the code\n",
    "imbalanced_columns = [col for col in df.columns if (df[col].value_counts(normalize=True).iloc[0] > threshold)]\n",
    "\n",
    "df = df.drop(columns=imbalanced_columns)\n",
    "\n",
    "# Rename and Sanitize Column Names\n",
    "df.rename(columns={'Duration_in_Minutes': 'duration'}, inplace=True)\n",
    "df.columns = [col.replace('{', '').replace('}', '').replace('[', '').replace(']', '').replace('\"', '').replace(':', '') for col in df.columns]\n",
    "\n",
    "# Convert Start_Time for Filtering Purposes\n",
    "# df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "# Step 7: Filtering Based on Dates\n",
    "def filter_data_based_on_date(df, start_date=None, end_date=None, before_date=None):\n",
    "    if start_date and end_date:\n",
    "        mask = (df['Start_Time'] >= start_date) & (df['Start_Time'] <= end_date)\n",
    "        return df.loc[mask]\n",
    "    elif before_date:\n",
    "        mask = df['Start_Time'] < before_date\n",
    "        return df.loc[mask]\n",
    "    return df  # Return original DataFrame if no conditions are met\n",
    "\n",
    "# Applying Filters\n",
    "subset_df = filter_data_based_on_date(df, start_date=pd.to_datetime('2020-03-10'), end_date=pd.to_datetime('2022-10-14'))\n",
    "subset_df_before = filter_data_based_on_date(df, before_date=pd.to_datetime('2020-03-10'))\n",
    "\n",
    "# Drop the 'Start_Time' column where necessary and exporting to CSV\n",
    "subset_df.drop(['Start_Time'], axis=1, inplace=True)\n",
    "subset_df_before.drop(['Start_Time'], axis=1, inplace=True)\n",
    "subset_df.to_csv('merged_covid.csv', index=False)\n",
    "subset_df_before.to_csv('merged_before.csv', index=False)\n",
    "\n",
    "# General Cleanup before Final CSV Export\n",
    "df.drop(['Start_Time'], axis=1, inplace=True)\n",
    "df.to_csv('merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e5eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
